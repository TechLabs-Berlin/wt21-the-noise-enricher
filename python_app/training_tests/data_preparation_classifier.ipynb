{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01562335",
   "metadata": {},
   "source": [
    "# classifying music styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "22dda4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch, torchaudio\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2c6fa2",
   "metadata": {},
   "source": [
    "## preparations\n",
    "\n",
    "download GTZAN dataset before: http://marsyas.info/downloads/datasets.html#\n",
    "\n",
    "save dataset in project directory (<code>path_root</code>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2456d159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths \n",
    "path_root = '/home/christian/Documents/sound_classifier' #change root directory here\n",
    "path_orgw = os.path.join(path_root, 'genres_original')\n",
    "path_chnk = os.path.join(path_root, 'audio_chunks')\n",
    "path_spec = os.path.join(path_root, 'spectrograms')\n",
    "\n",
    "# dictionary of all genres with tracks\n",
    "genres = os.listdir(path_orgw)\n",
    "tracks = {x:os.listdir(os.path.join(path_orgw, x)) for x in genres}\n",
    "\n",
    "# make folder structure\n",
    "os.mkdir('audio_chunks')\n",
    "os.mkdir('spectrograms')\n",
    "\n",
    "for g in genres:\n",
    "    os.mkdir(os.path.join(path_root, 'audio_chunks', g))\n",
    "    os.mkdir(os.path.join(path_root, 'spectrograms', g))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7a40bc",
   "metadata": {},
   "source": [
    "## split into chunks of 3 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9daa304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting size of audio snipplets in ms\n",
    "chunk_size = 3000\n",
    "\n",
    "for genre in genres:\n",
    "    for counttrack, file in enumerate(tracks[genre]):\n",
    "        try: \n",
    "            infile = os.path.join(path_orgw, genre, file)\n",
    "            audio = AudioSegment.from_wav(infile)\n",
    "            audio_length = len(audio)\n",
    "\n",
    "            chunk_nmbr = audio_length//chunk_size\n",
    "            chunk_pcs  = np.arange(0, chunk_nmbr+1)*chunk_size\n",
    "\n",
    "            for countfile, i in enumerate(range(len(chunk_pcs)-1)):\n",
    "                outfile = str(genre+'_'+str(counttrack)+'_'+str(countfile)+'.wav')\n",
    "                outfile = os.path.join(path_chnk, genre, outfile)\n",
    "                audio[chunk_pcs[i]:chunk_pcs[i+1]].export(outfile, format='wav')\n",
    "        except:\n",
    "            print('error: ' + str(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe75b4b",
   "metadata": {},
   "source": [
    "## create spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d143d67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_spec = torchaudio.transforms.Spectrogram(n_fft=515, power=None, return_complex=True)\n",
    "\n",
    "for genre in genres:\n",
    "    chunks = os.listdir(os.path.join(path_chnk, genre))\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        infile = os.path.join(path_chnk, genre, chunk)\n",
    "        waveform, sr_input = torchaudio.load(infile)\n",
    "        spec = trans_spec(waveform)\n",
    "        outfile = chunk[:-4] + '.pt'\n",
    "        outfile = os.path.join(path_spec, genre, outfile) \n",
    "        torch.save(spec, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5770473",
   "metadata": {},
   "source": [
    "## create dataset .csv file for dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "21557192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dx = []\n",
    "\n",
    "for genre_no, genre in enumerate(genres):\n",
    "    filenames = os.listdir(os.path.join(path_spec, genre))\n",
    "    for file in filenames:\n",
    "        dx.append([str('spectrograms/'+genre+'/'+file), genre_no])\n",
    "\n",
    "dx = pd.DataFrame(dx, columns=['file', 'category'])\n",
    "\n",
    "dx_train, dx_test = train_test_split(dx, test_size=.2)\n",
    "\n",
    "dx_train.to_csv(os.path.join(path_root, 'dataset_files_train.csv'), index=None)\n",
    "dx_test.to_csv(os.path.join(path_root, 'dataset_files_test.csv'), index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
